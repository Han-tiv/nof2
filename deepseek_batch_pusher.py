import json
import aiohttp
import asyncio
import logging
import time
import re
from config import DEEPSEEK_API_KEY, DEEPSEEK_MODEL, DEEPSEEK_URL
from database import redis_client
from volume_stats import (
    calc_volume_compare, get_open_interest, get_funding_rate, get_24hr_change, calc_smart_sentiment,
    get_oi_history, get_top_position_ratio, get_top_account_ratio, get_global_account_ratio)
from account_positions import account_snapshot, tp_sl_cache

required_intervals = ["1d", "4h", "1h", "15m", "5m"]
batch_cache = {}

KEY_REQ = "deepseek_analysis_request_history"
KEY_RES = "deepseek_analysis_response_history"

def add_to_batch(symbol, interval, klines, indicators):
    if symbol not in batch_cache:
        batch_cache[symbol] = {}
    batch_cache[symbol][interval] = {"klines": klines, "indicators": indicators}


def _is_ready_for_push():
    for _, cycles in batch_cache.items():
        for tf in required_intervals:
            if tf not in cycles:
                return False
    return True

def sentiment_to_signal(score):
    if score >= 85:
        return "ğŸš¨ æç«¯è¿‡çƒ­ | è­¦æƒ•é¡¶éƒ¨åè½¬"
    if score >= 70:
        return "ğŸŸ¢ ç‰›åŠ¿å¼ºåŠ² |"
    if score >= 50:
        return "âšª ä¸­æ€§éœ‡è¡ | è€å¿ƒç­‰å¾…çªç ´"
    if score >= 30:
        return "ğŸŸ¡ ææ…Œç¼“è§£"
    return "ğŸ”¥ æåº¦ææ…Œ"

def _read_prompt():
    try:
        with open("prompt.txt", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return "ä½ æ˜¯ä¸€åä¸“ä¸šé‡åŒ–ç­–ç•¥åˆ†æå¼•æ“ï¼Œè¯·ä¸¥æ ¼è¾“å‡º JSON æ•°ç»„æˆ– JSON å¯¹è±¡å½¢å¼çš„äº¤æ˜“ä¿¡å·ã€‚"

def _format_dataset(dataset):
    start_time = time.time()  # â± è®°å½•å¼€å§‹æ—¶é—´
    text = []
    
    # ğŸ§  è´¦æˆ·èµ„é‡‘ & æŒä»“ä¿¡æ¯
    account = account_snapshot

    text.append("========= ğŸ“Œ å½“å‰è´¦æˆ·èµ„é‡‘çŠ¶æ€ =========")
    text.append(f"ğŸ’° æ€»æƒç›Š Balance: {round(account['balance'], 4)}")
    text.append(f"ğŸ”“ å¯ç”¨ä½™é¢ Available: {round(account['available'], 4)}")
    text.append(f"ğŸ“‰ æ€»æœªå®ç°ç›ˆäº PnL: {round(account['total_unrealized'], 4)}")

    if account["positions"]:
        text.append("\nğŸ“Œ å½“å‰æŒä»“:")

        for p in account["positions"]:
            amt = float(p["size"])
            entry = float(p["entry"])
            mark = float(p["mark_price"])
            pnl = float(p["pnl"])
            lev = int(p["leverage"])

            side_icon = "ğŸŸ¢ å¤š" if amt > 0 else "ğŸ”´ ç©º"

            # ç›ˆäºç™¾åˆ†æ¯”
            if entry > 0:
                pnl_pct = round((mark - entry) / entry * 100, 2) if amt > 0 else round((entry - mark) / entry * 100, 2)
            else:
                pnl_pct = 0

            # ğŸ”¥ æ„å»ºæŒä»“åŸºæœ¬ä¿¡æ¯
            line = (
                f"{p['symbol']} | {side_icon} | æ•°é‡ {abs(amt)} | "
                f"å…¥åœº {entry} â†’ å½“å‰ä»·æ ¼ {mark} | ğŸ’µ ç›ˆäº {pnl} ({pnl_pct}%)"
            )

            # ğŸ”¥ æ·»åŠ  TP/SL ä¿¡æ¯
            pos_side = "LONG" if amt > 0 else "SHORT"
            tp_sl_orders = tp_sl_cache.get(p['symbol'], {}).get(pos_side, [])
            if tp_sl_orders:
                tp_sl_lines = [f"{o['type']}={o['stopPrice']}" for o in tp_sl_orders]
                line += " | TP/SL: " + ", ".join(tp_sl_lines)
            else:
                line += " | TP/SL: æ— "

            text.append(line)

    else:
        text.append("\nğŸ“Œ å½“å‰æ— æŒä»“")

    for symbol, cycles in dataset.items():
        text.append(f"\n============ {symbol} å¤šå‘¨æœŸè¡Œæƒ…å¿«ç…§ ============")
        # ğŸ”¥ ç»Ÿä¸€è·å–ä¸€æ¬¡åŸºç¡€æ•°æ®ï¼ˆé¿å…é‡å¤APIè°ƒç”¨ï¼‰
        fr = get_funding_rate(symbol)
        p24 = get_24hr_change(symbol)

        if p24:
            text.append(f"â€¢ 24h æ¶¨è·Œå¹…: {p24['priceChangePercent']}% â†’ æœ€æ–° {p24['lastPrice']} (é«˜ {p24['highPrice']} / ä½ {p24['lowPrice']})")
            text.append(f"â€¢ 24h æˆäº¤é¢: {round(p24['quoteVolume']/1e6, 2)}M USD")
            
        text.append(f"ğŸ’° å½“å‰èµ„é‡‘è´¹ç‡ Funding Rate: {fr if fr else 'æœªçŸ¥'}")
        
        for interval, data in cycles.items():
            kl = data["klines"]
            ind = data["indicators"]
            last = kl[-1]

            text.append(f"\n--- {interval} ---")
            text.append(f"ğŸ“Œ å½“å‰å‘¨æœŸæ”¶ç›˜ä»·æ ¼: {last['Close']}")
            
            period = interval  # å‘¨æœŸåŠ¨æ€è·Ÿéš interval

            # â­ æ·±åº¦èµ„é‡‘æŒ‡æ ‡ï¼ˆå‘¨æœŸè‡ªé€‚åº” + è‡ªåŠ¨ç¼“å­˜ï¼Œæ— é‡å¤è¯·æ±‚ï¼‰
            try:
                oi_hist = get_oi_history(symbol, period, limit=10)
                big_pos = get_top_position_ratio(symbol, period, limit=1)
                big_acc = get_top_account_ratio(symbol, period, limit=1)
                global_acc = get_global_account_ratio(symbol, period, limit=1)
            except Exception:
                oi_hist = big_pos = big_acc = global_acc = None
                
            oi = get_open_interest(symbol)
            text.append(f"ğŸ§± å½“å‰æ°¸ç»­æœªå¹³ä»“é‡ OI: {oi if oi else 'æœªçŸ¥'}")
            if oi_hist:
                arr = [round(i["openInterest"], 2) for i in oi_hist][-10:]
                text.append(f"â€¢æœ€æ–°10æ¡å†å² OI æ•°æ®è¶‹åŠ¿: {arr}")

            if big_pos:
                text.append(f"â€¢ å¤§æˆ·æŒä»“é‡å¤šç©ºæ¯”: {big_pos[-1]['ratio']} (å¤š {big_pos[-1]['long']}, ç©º {big_pos[-1]['short']})")

            if big_acc:
                text.append(f"â€¢ å¤§æˆ·è´¦æˆ·æ•°å¤šç©ºæ¯”: {big_acc[-1]['ratio']} (å¤š {big_acc[-1]['long']}, ç©º {big_acc[-1]['short']})")

            if global_acc:
                text.append(f"â€¢ å…¨ç½‘å¤šç©ºäººæ•°æ¯”: {global_acc[-1]['ratio']} (å¤š {global_acc[-1]['long']}, ç©º {global_acc[-1]['short']})")
            
            # ğŸ”¥ CVD ä¸ ATRï¼ˆä½  indicators.py ç”Ÿæˆçš„ï¼‰
            text.append("\nğŸ“Œ CVD æŒ‡æ ‡:")
            for key in ["CVD", "CVD_MOM", "CVD_DIVERGENCE", "CVD_PEAKFLIP", "CVD_NORM"]:
                if key in ind:
                    text.append(f"{key}: {ind[key]}")

            # =========================
            # â­ Smart Sentiment å¤šå› å­è¯„åˆ† + æ“ä½œä¿¡å·
            # =========================
            try:
                sentiment = calc_smart_sentiment(symbol, period)
                score = sentiment["sentiment_score"]
                fac = sentiment["factors"]
                signal_text = sentiment_to_signal(score)

                text.append("\nğŸ“Œ Smart Sentiment Score:")
                # text.append(f"ğŸ¯ æƒ…ç»ªè¯„åˆ†: {score}/100  â†’  {signal_text}")
                text.append(f"ğŸ¯ æƒ…ç»ªè¯„åˆ†: {score}/100")

                text.append(f"ğŸ“Š åˆ†é¡¹å› å­(å½’ä¸€åŒ–):")
                text.append(f"Â· OIæƒ…ç»ª: {fac['open_interest']}")
                text.append(f"Â· Fundingæƒ…ç»ª: {fac['funding_rate']}")
                text.append(f"Â· å¤§æˆ·æƒ…ç»ª: {fac['big_whales']}")
                text.append(f"Â· æ•£æˆ·åå‘æƒ…ç»ª: {fac['retail_inverse']}")
                text.append(f"Â· æˆäº¤é‡æƒ…ç»ª: {fac['volume_emotion']}")

            except Exception as e:
                text.append("\nğŸ“Œ Smart Sentiment Score: è®¡ç®—å¤±è´¥")
                logging.warning(f"Sentiment calc error: {e}")

            text.append("\nğŸ“Œ æ³¢åŠ¨ç‡æŒ‡æ ‡:")
            if "ATR" in ind:
                text.append(f"ATR: {ind['ATR']}")

            # ğŸ”¥ ä¸»åŠ¨ä¹°å–é‡åˆ†æ
            last_buy = float(kl[-1]["TakerBuyVolume"])
            last_sell = float(kl[-1]["TakerSellVolume"])
            last_vol = float(kl[-1]["Volume"])
            ratio = round(last_buy / last_vol * 100, 2) if last_vol > 0 else 0

            text.append("\nğŸ“Œ ä¸»åŠ¨äº¤æ˜“é‡:")
            text.append(f"ä¸»åŠ¨ä¹°å…¥é‡(Taker Buy): {last_buy}")
            text.append(f"ä¸»åŠ¨å–å‡ºé‡(Taker Sell): {last_sell}")
            text.append(f"ä¸»åŠ¨ä¹°å…¥å æ¯”: {ratio}%")

            # ğŸ”¥ æˆäº¤é‡å¯¹æ¯”ï¼ˆæ¯ä¸ªå‘¨æœŸç‹¬ç«‹ï¼‰
            vol_info = calc_volume_compare(kl)
            if vol_info:
                text.append("\nğŸ“Œ æˆäº¤é‡å¯¹æ¯”:")
                text.append(f"å½“å‰æˆäº¤é‡: {vol_info['current_volume']}")
                text.append(f"100æ ¹å‡é‡: {vol_info['average_volume_100']}")
                text.append(f"å½“å‰/å‡é‡æ¯”å€¼: {vol_info['ratio']}")
                
            opens = [k["Open"] for k in kl]
            highs = [k["High"] for k in kl]
            lows = [k["Low"] for k in kl]
            closes = [k["Close"] for k in kl]
            volumes = [k["Volume"] for k in kl]

            text.append("\nğŸ“Œ Kçº¿æ•°ç»„æ ¼å¼ä»æ—§ â†’ æ–°:")
            text.append(f"open: {opens}")
            text.append(f"high: {highs}")
            text.append(f"low: {lows}")
            text.append(f"close: {closes}")
            text.append(f"volume: {volumes}")
            
    # ğŸ”¥ è°ƒè¯•çš„æ—¶å€™ä½¿ç”¨
    # text.append("\nğŸ§  ç°åœ¨è¯·åˆ†æå¹¶è¾“å‡ºå†³ç­–ï¼ˆæ€ç»´é“¾ + JSONï¼‰")
    text.append("\nğŸ§  ç°åœ¨è¯·åˆ†æå¹¶è¾“å‡ºå†³ç­–ï¼ˆç®€æ´æ€ç»´é“¾ < 150 å­— + JSONï¼‰")

    end_time = time.time()  # â± è®°å½•ç»“æŸæ—¶é—´
    elapsed = end_time - start_time
    print(f"[_format_dataset] å‡½æ•°æ‰§è¡Œè€—æ—¶: {elapsed:.3f} ç§’")  # æ‰“å°è€—æ—¶
    return "\n".join(text)

# ğŸ” ä¼˜å…ˆè§£æ <decision> æ ‡ç­¾å†…éƒ¨ JSON
def _extract_decision_block(content: str):
    match = re.search(r"<decision>([\s\S]*?)</decision>", content, flags=re.I)
    if not match:
        return None
    block = match.group(1).strip()
    try:
        parsed = json.loads(block)
        if isinstance(parsed, list):
            return parsed
    except:
        pass
    return None

def _extract_all_json(content: str):
    """
    æ”¯æŒï¼š
      {â€¦}{â€¦}
      [{â€¦},{â€¦}]
      å•ä¸ª {â€¦}
    åªä¿ç•™ action å­˜åœ¨çš„ JSON
    """
    results = []

    # 1) JSON æ•°ç»„
    try:
        parsed = json.loads(content)
        if isinstance(parsed, list):
            return [x for x in parsed if isinstance(x, dict) and "action" in x]
    except:
        pass

    # 2) ä½¿ç”¨æ­£åˆ™æå–å¤šä¸ª { }
    matches = re.findall(r'\{[^{}]*\}', content, flags=re.S)
    for m in matches:
        try:
            obj = json.loads(m)
            if isinstance(obj, dict) and "action" in obj:
                results.append(obj)
        except:
            pass

    return results if results else None

async def push_batch_to_deepseek():
    if not _is_ready_for_push():
        return None

    dataset = batch_cache.copy()
    batch_cache.clear()

    timestamp = int(time.time() * 1000)

    loop = asyncio.get_running_loop()

    # ===========================
    # ğŸ§  1) é˜»å¡ CPU çš„ä»»åŠ¡æ”¾è¿›çº¿ç¨‹æ± é¿å…å¡ä½äº‹ä»¶å¾ªç¯
    # ===========================
    formatted_dataset = await loop.run_in_executor(None, _format_dataset, dataset)
    system_prompt = await loop.run_in_executor(None, _read_prompt)

    payload = {
        "model": DEEPSEEK_MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": formatted_dataset}
        ],
        "temperature": 0.1,
        "max_tokens": 8000,  # ğŸ”¥ å¢åŠ tokené™åˆ¶ï¼Œç»™æ¨ç†è¶³å¤Ÿç©ºé—´
        "stream": False
    }

    # push request history
    redis_client.lpush(KEY_REQ, json.dumps({
        "timestamp": timestamp,
        "request": formatted_dataset
    }, ensure_ascii=False))

    start = time.perf_counter()

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                DEEPSEEK_URL,
                json=payload,
                headers={"Authorization": f"Bearer {DEEPSEEK_API_KEY}"}
            ) as resp:

                raw = await resp.text()
                print("DeepSeek å·²è¿”å›", time.time())
                cost = round((time.perf_counter() - start) * 1000, 2)
                
                # ===============================
                # ğŸ§  2) JSON è§£æä¹Ÿæ”¾å…¥çº¿ç¨‹æ± 
                # ===============================
                def parse_ai_response(raw):
                    try:
                        root = json.loads(raw)
                        content = root["choices"][0]["message"]["content"]
                    except Exception as e:
                        return None

                    # ä¼˜å…ˆ <decision>
                    d = _extract_decision_block(content)
                    if d:
                        return d
                    
                    # fallback
                    return _extract_all_json(content)

                signals = await loop.run_in_executor(None, parse_ai_response, raw)

                # save response
                redis_client.lpush(KEY_RES, json.dumps({
                    "timestamp": timestamp,
                    "response_raw": raw,
                    "response_json": signals,
                    "status_code": resp.status,
                    "cost_ms": cost
                }, ensure_ascii=False))

                print(f"\nâ± DeepSeek å“åº”è€—æ—¶: {cost} ms   HTTP: {resp.status}")
                # print("ğŸ§  AI è§£æåä¿¡å·:", signals)

                return signals

    except Exception as e:
        logging.error(f"âŒ DeepSeek è°ƒç”¨å¤±è´¥ï¼š{e}")
        return None
